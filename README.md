# DeKalb Exhibition
## Methodology
### Team: John Lauermann, Alex Strada, Yuanhao Wu, Nathan Smash
 
This document describes the methodology used to create maps for Strada’s Spring 2025 exhibition in the DeKalb gallery. We created a series of maps showing community district level data on housing and neighborhood demographics. We then designed a series of 2D map templates for exhibition and 3D maps as digital companions.
 
## Data Gathering

Boundary files were obtained for NYC Community Districts and 2022 Census TigerLine tracts. Both were projected into UTM Zone 18N. Tracts in the five boroughs were extracted using a query and then water areas were clipped using district boundaries. 

### US Census
We compiled a collection of variables from the Census Bureau and NYC Open Data. See [variable documentation](https://docs.google.com/spreadsheets/d/1ocsovQU9sfGW3KTDgE4AntTEQhZ-ztR_e0dDfXoxsf8/edit?usp=sharing) here. 

Demographic variables were collected from ACS 2022 5yr estimates using the Census API via tidycensus. 

1. To calculate tract level maps, derivative variables were calculated in R using code_ACS22_tract.R  
    - Then data_ACS22_tract.csv was joined to Census TigerLine tract boundaries based on GEOID. 
    - The join was exported to exhibitionmaps.gdb/data_ACS22_tract using data_ACS22_tract.fieldmap to control for field types mis-read by ArcGIS
2. To calculate community district maps, tract boundaries were spatial joined to CD boundaries based on a largest overlap relationship. 
    - The resulting table tracts_byCD.csv was merged with the tract data on in R using code_ACS22_CD.R  
    - We then summarized tract counts by CD number.
    - And joined the resulting table data_ACS22_CD.csv back to the CD boundaries based on the same CD number.
    - The join was exported to exhibitionmaps.gdb/data_ACS_CD

### NYC Open DataEvictions

We also pulled several datasets from NYC Open DataEvictions data was collected from Evictions from NYC Open Data. It shows the data from 2017 to present (11/1/2024). After consultation with the team, we chose to query only those 

1. Due to the large volume of data, collecting it via API was not feasible because of its 1,000-line limitation. Therefore, we downloaded the dataset directly as Evictions.csv
    - We then use Python to locate each point based on the longitude and latitude columns in the dataset and export the results as a shapefile named Evictions.shp, saved in the Evictions_Geo folder. The Python Code is named Evictions_311_Data_Col.ipynb
    - We import the shapefile into the map and exported the features, storing the data in exhibitionmaps.gdb/Evictions

### 311 Data

311 data was collected from 311 Service Requests from 2010 to Present (11/1/2024) from NYC Open Data.
1. Due to the large amount of data, it is impossible to collect it through API since it has the limitation of 1,000 lines. It also would take a long time to download the whole dataset.
    - To get the data, We first put some filters on the data. To match with the Evictions data, we first put a filter on Created Date to get the data from 1/12017. We then put a filter on Complaint Type, we collect all the data that contains “Homeless”. We put all the filtered data into 311_Service_Requests.csv
    - After collecting all, We use Python to locate each point based on the longitude and latitude columns in the dataset and export the results as a shapefile named 311_Call.shp, saved in the 311_Call folder. The Python Code is named Evictions_311_Data_Col.ipynb
    - We import the shapefile into the map and exported the features, storing the data in exhibitionmaps.gdb/311_Call


